---
output: html_document
editor_options: 
  chunk_output_type: console
---

# eBird Data {#ebird}

## Introduction {#ebird-intro}

eBird data are collected and organized around the concept of a checklist, representing observations from a single birding event, such as a 1 km walk through a park or 15 minutes observing bird feeders in your backyard. Each checklist contains a list of species observed, counts of the number of individuals seen of each species, the location and time of the observations, and a measure of the effort expended while collecting these data. The following image depicts a typical eBird checklist as viewed [on the eBird website](https://ebird.org/view/checklist/S46908897):

![](images/ebird-data_checklist.png)

Although eBird collects semi-structured citizen science data, three elements of eBird checklists distinguish them from data collected via most other similar citizen science projects. First, eBird checklist require users to specify the survey protocol they used, whether it's traveling, stationary, incidental (i.e. if the observations were collected when birding was not the primary activity), or one of the other protocols. Second, in addition to typical information on when and where the data were collected, checklists contain effort information specifying how long the observer searched, how far they traveled, and how many observers were part of the party. Finally, observers are asked to indicate whether they are reporting all the birds they were able to identify. Checklists with all species reported, known as **complete checklists**, enable researchers to identify which species were not detected (rather than just not reported). These inferred non-detections allow data to be *zero-filled*, so there's a zero count for any species not recorded. Complete checklists with effort information facilitate robust analyses, and thus represent the gold standard of eBird checklists. Because of these factors, eBird data are often referred to as **semi-structured** [@kellingFindingSignalNoise2018].

eBird data are typically distributed in two parts: observation data and checklist data. In the observation dataset, each row corresponds to the sighting of a single species on a checklist, including the count and any other species-level information (e.g. age, sex, species comments, etc.). In the checklist dataset, each row corresponds to a checklist, including the date, time, location, effort (e.g. distance traveled, time spent, etc.), and any additional checklist-level information (e.g. whether this is a complete checklist or not). The two datasets can be joined together using a unique checklist identifier (sometimes referred to as the sampling event identifier).

In this chapter, we'll download eBird data and demonstrate how to use the R package `auk` to extract subsets of the data for analysis. Next, we'll show how to import the data into R and zero-fill it to produce detection/non-detection data suitable for modeling species distribution and abundance. Finally, we'll perform some pre-processing steps required to ensure proper analysis of the data.

## Downloading data {#ebird-download}

The observation and checklist data are released as tab-separated text files referred to as the *eBird Basic Dataset (EBD)* and the *Sampling Event Data (SED)*, respectively. These files are released monthly and contain all validated bird sightings in the eBird database at the time of release. The EBD (i.e. the observation data) can be downloaded in its entirety or a subset for a given species, region, or time period can be requested via the "Custom Download" form. We strongly recommend against attempting to download the complete EBD since it's well over 100GB at the time of writing. Instead, we will demonstrate a workflow using the "Custom Download" approach. In what follows, we will assume you have followed the instructions for requesting access to eBird data outlined in [the previous chapter](#intro-setup-ebird).

In the interest of making examples concrete, throughout this book, we'll use the specific example of [Wood Thrush](https://ebird.org/species/woothr) observations from Georgia (the US state, not the country) in June for our analyses. We'll start by downloading the corresponding eBird observations by visiting the [eBird Basic Dataset](https://ebird.org/data/download/ebd) download page and filling out the Custom Download form to request eBird data from Georgia.

![](images/ebird-data_download.png)

Once the data are ready, you will an email with a download link. The downloaded data will be in a compressed .zip format, and should be unarchived. The resulting directory will contain a text file (e.g. `ebd_US-GA_woothr_relMar-2023.txt`) containing all the Wood Thrush observations from Georgia. The `relMar-2023` component of the file name describes which version of the EBD this dataset came from; in this case it's the March 2023 release.

For some uses cases, such as making a map of eBird observations, the EBD will be sufficient. However, for many applications, including all analyses in this book, we need both the detections and non-detections (i.e. the checklists where the species was not detected). To infer the non-detections we'll need the full population of checklists for our region and time period of interest, which is provided in the form of the SED. Unlike the EBD, the SED can only be downloaded in it's entirety rather than as a custom subset; however, the file is much smaller (\~4GB at the time of writing) and therefore easier to deal with.

Download the **Sampling Event Data** now, then use a compression utility to uncompress the `.tar` file and the `.txt.gz` file it contains to produce a text file (e.g. `ebd_sampling_relMar-2023.txt`). It's **absolutely critical to confirm that the versions of the EBD and SED are the same**, for example both files have `relMar-2023` in the name, otherwise they will be mismatched when we later try to combine them. Move these the EBD and SED text files to the central location for eBird data that you set in the [Introduction](#intro-setup-ebird). To be reminded of the path to this directory use `auk::auk_get_ebd_path()`.

## Data extraction with `auk` {#ebird-filter}

eBird contains an impressive amount of data (over 1 billion bird observations!); however, this makes the data particularly challenging to work with. Very large text files can't be opened in R, Excel, or most other software because they may require more memory than your computer has access to. In addition, even if these files can be read into R, they can be extremely slow to process. Fortunately, the R package `auk` has been specifically designed to extract subsets of data from the EBD and SED for analysis using the Unix command line text processing utility AWK. AWK only allows for coarse filtering, but the data can always be further refined once in R. With this in mind, **the goal when using `auk` should always be to subset the EBD and SED text files down to a manageable size**, small enough that they can be imported into R for further processing or analysis. In our case, that will mean extracting Wood Thrush records from Georgia in June.

Filtering the eBird data using `auk` requires three steps. First, reference the EBD and SED text files using the function `auk_ebd()`. If you've followed the setup instruction in the [Introduction](#intro-setup-ebird) and the [previous section](#ebird-download), you'll have these text files on your computer and will have pointed `auk` to the directory they're stored in using `auk_set_ebd_path()`.

Before running any of the following code, create an [RStudio project](https://r4ds.hadley.nz/workflow-scripts.html#projects) for following along with this book. The project will be a self contained space for all the code, input data, and outputs that comprise the lessons in this book. In addition, using a project will ensure your working directory is set to the project directory.

Downloading and extracting eBird data in this section can be time consuming and laborious. If you would prefer to skip to the next section, download the [data package](https://github.com/ebird/ebird-best-practices/raw/master/data/data.zip) mentioned in the Introduction and jump to the {next section}(#ebird-zf). Just make sure you load the packages in the first code chunk before proceeding.

```{r}
library(sf)
library(gridExtra)
library(tidyverse)
library(auk)

# setup data directory
dir.create("data", showWarnings = FALSE, recursive = TRUE)

ebd <- auk_ebd("ebd_US-GA_woothr_relMar-2023.txt", 
               file_sampling = "ebd_sampling_relMar-2023.txt")
```

Next, define the filters that you want to apply to the EBD. Each field that you can filter on has an associated function. For example, we'll filter to observations from Georgia with `auk_state()`, in June of any year with `auk_date()`, restrict observations to those from either Stationary or Traveling protocols with `auk_protocol()`, and only keep complete checklists with `auk_complete()` since we intend to zero-fill the data. For a full list of possible filters, [consult the package documentation](https://cornelllabofornithology.github.io/auk/reference/index.html#section-filter).

Some of the filtering work has already been done for us by downloading an EBD subset via the Custom Download form: we only have observations for Wood Thrush in Georgia. However, it's **critical that we filter the EBD and SED in exactly the same way** to produce exactly the same population of checklists, so we include the filter for Georgia even though it's redundant for the EBD.

```{r}
ebd_filters <- ebd %>% 
  # georgia, make sure to use the ebird region code here
  auk_state(state = "US-GA") %>% 
  # june, use * to get data from any year
  auk_date(date = c("*-06-01", "*-06-30")) %>% 
  # restrict to the standard traveling and stationary count protocols
  auk_protocol(protocol = c("Stationary", "Traveling")) %>%
  # only complete checklists to facilitate zero-filling
  auk_complete()
ebd_filters
```

Printing the object `ebd_filters` above shows what filters have been set. At this point, we've only defined the filters, not applied them to the data. The last step is to use `auk_filter()` to compile the filters into an AWK script and run it to produce two output files: one for the EBD and one for the SED. **This step typically takes at least 30 minutes to run since the SED file is so large.** As a result, it's wise to wrap this in an `if` statement, so it's only run once. As noted in the [Introduction](#intro-setup-software), Windows users will need to [install Cygwin](https://www.cygwin.com/) for this next step to work.

```{r}
# output files
f_ebd <- "data/observations_woothr_june_us-ga.txt"
f_sed <- "data/checklists_june_us-ga.txt"

# only run if the output files don't already exist
if (!file.exists(f_ebd)|| !file.exists(f_sed)) {
  auk_filter(ebd_filters, file = f_ebd, file_sampling = f_sed)
}
```

The resulting SED file is now about 13MB, compared to over 4GB for the original dataset, which means it can easily be read into R!

## Importing and zero-filling {#ebird-zf}

The previous step left us with two tab separated text files, one for the EBD (i.e. observation data) and one for the SED (i.e. checklist data). Next, we'll use [`auk_zerofill()`](https://cornelllabofornithology.github.io/auk/reference/auk_zerofill.html) to read these two files into R and combine them together to produce zero-filled, detection/non-detection data (also called presence/absence data). To just read the EBD or SED, but not combine them, use [`read_ebd()`](https://cornelllabofornithology.github.io/auk/reference/read_ebd.html) or [`read_sampling()`](https://cornelllabofornithology.github.io/auk/reference/read_ebd.html), respectively.

```{r}
zf <- auk_zerofill(f_ebd, f_sed, collapse = TRUE)
```

When any of the read functions from `auk` are used, two important processing steps occur by default behind the scenes. 1. **Taxonomic rollup**: eBird observations can be made at levels below species (e.g. subspecies) or above species (e.g. a bird that was only identified as Duck sp.); however, for most uses we'll want observations at the species level. [`auk_rollup()`](https://cornelllabofornithology.github.io/auk/reference/auk_rollup.html) is applied by default when [`auk_zerofill()`](https://cornelllabofornithology.github.io/auk/reference/auk_zerofill.html) is used. It drops all observations not identifiable to a species and rolls up all observations reported below species to the species level. 2. **Collapsing group checklist**: eBird also allows for [group checklists](https://support.ebird.org/en/support/solutions/articles/48000625567-checklist-sharing-and-group-accounts), those shared by multiple users. These checklists lead to duplication or near duplication of records within the dataset and the function [`auk_unique()`](https://cornelllabofornithology.github.io/auk/reference/auk_unique.html), applied by default by [`auk_zerofill()`](https://cornelllabofornithology.github.io/auk/reference/auk_zerofill.html), addresses this by only keeping one independent copy of each checklist.

Finally, by default [`auk_zerofill()`](https://cornelllabofornithology.github.io/auk/reference/auk_zerofill.html) returns a compact representation of the data, consisting of a list of two data frames, one with checklist data and the other with observation data; the use of `collapse = TRUE` combines these into a single data frame, which will be easier to work with.

Before continuing, we'll transform some of the variables to a more useful form for modelling. We convert time to a decimal value between 0 and 24, and we force the distance travelled to 0 for stationary checklists. Notably, eBirders have the option of entering an "X" rather than a count for a species, to indicate that the species was present, but they didn't keep track of how many individuals were observed. During the modeling stage, we'll want the `observation_count` variable stored as an integer and we'll convert "X" to `NA` to allow for this.

```{r}
# function to convert time observation to hours since midnight
time_to_decimal <- function(x) {
  x <- hms(x, quiet = TRUE)
  hour(x) + minute(x) / 60 + second(x) / 3600
}

# clean up variables
zf <- zf %>% 
  mutate(
    # convert X to NA
    observation_count = if_else(observation_count == "X", 
                                NA_character_, observation_count),
    observation_count = as.integer(observation_count),
    # effort_distance_km to 0 for non-travelling counts
    effort_distance_km = if_else(protocol_type != "Traveling", 
                                 0, effort_distance_km),
    # convert time to decimal hours since midnight
    hours_of_day = time_to_decimal(time_observations_started),
    # split date into year and day of year
    year = year(observation_date),
    day_of_year = yday(observation_date)
  )
```

## Accounting for variation in detectability {#ebird-detect}

As discussed in the [Introduction](#intro-intro), variation in effort between checklists makes inference challenging, because it is associated with variation in detectability. When working with semi-structured datasets like eBird, one approach to dealing with this variation is to impose some more consistent structure on the data by filtering observations on the effort variables. This reduces the variation in detectability between checklists. Based on our experience working with these data, we suggest restricting checklists to less than 5 hours long and 5 km in length, and with 10 or fewer observers. Furthermore, we'll only consider data from the past 10 years (2013-2022).

```{r ebird-detect}
# additional filtering
zf_filtered <- zf %>% 
  filter(
    # effort filters
    duration_minutes <= 5 * 60,
    effort_distance_km <= 5,
    # last 10 years of data
    year >= 2013,
    # 10 or fewer observers
    number_observers <= 10)
```

Finally, there are a large number of variables in the EBD that are redundant (e.g. both state names *and* codes are present) or unnecessary for most modeling exercises (e.g. checklist comments and Important Bird Area codes). These can be removed at this point, keeping only the variables we want for modelling. Then we'll save the resulting zero-filled observations for use in later chapters.

```{r ebird-detect-clean}
checklists <- zf_filtered %>% 
  select(checklist_id, observer_id, sampling_event_identifier,
         scientific_name,
         observation_count, species_observed, 
         state_code, locality_id, latitude, longitude,
         protocol_type, all_species_reported,
         observation_date, year, day_of_year,
         hours_of_day, 
         duration_minutes, effort_distance_km,
         number_observers)
write_csv(checklists, "data/checklists-zf_woothr_june_us-ga.csv", na = "")
```

If you'd like to ensure you're using exactly the same data as was used to generate this book, download the [data package](https://github.com/ebird/ebird-best-practices/raw/master/data/data.zip) mentioned in the [setup instructions](#intro-setup-data) and place the contents in the `data/` subdirectory of your project directory.

## Exploratory analysis and visualization {#ebird-explore}

Before proceeding to fitting species distribution models with these data, it's worth exploring the dataset to see what we're working with. Let's start by making a simple map of the observations. This map uses GIS data available for [download in the data package](https://github.com/ebird/ebird-best-practices/raw/master/data/data.zip). Place the contents of the zip file in the `data/` subdirectory of your project directory. We'll use an [USA Albers contiguous equal area conic](https://spatialreference.org/ref/esri/usa-contiguous-albers-equal-area-conic/) projection for all the maps throughout this book.

```{r}
#| label: ebird-explore-map
# load and project gis data 
map_proj <- st_crs("ESRI:102003")
ne_land <- read_sf("data/gis-data.gpkg", "ne_land") %>% 
  st_transform(crs = map_proj) %>% 
  st_geometry()
ne_country_lines <- read_sf("data/gis-data.gpkg", "ne_country_lines") %>% 
  st_transform(crs = map_proj) %>% 
  st_geometry()
ne_state_lines <- read_sf("data/gis-data.gpkg", "ne_state_lines") %>% 
  st_transform(crs = map_proj) %>% 
  st_geometry()
ga_boundary <- read_sf("data/gis-data.gpkg", "ne_states") %>% 
  filter(state_code == "US-GA") %>% 
  st_transform(crs = map_proj) %>% 
  st_geometry()

# prepare ebird data for mapping
checklists_sf <- checklists %>% 
  # convert to spatial points
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326) %>% 
  st_transform(crs = map_proj) %>% 
  select(species_observed)

# map
par(mar = c(0.25, 0.25, 0.25, 0.25))
# set up plot area
plot(st_geometry(checklists_sf), col = NA)
# contextual gis data
plot(ne_land, col = "#dddddd", border = "#888888", lwd = 0.5, add = TRUE)
plot(ga_boundary, col = "#cccccc", border = NA, add = TRUE)
plot(ne_state_lines, col = "#ffffff", lwd = 0.75, add = TRUE)
plot(ne_country_lines, col = "#ffffff", lwd = 1.5, add = TRUE)
# ebird observations
# not observed
plot(filter(checklists_sf, !species_observed),
     pch = 19, cex = 0.1, col = alpha("#555555", 0.25),
     add = TRUE)
# observed
plot(filter(checklists_sf, species_observed),
     pch = 19, cex = 0.3, col = alpha("#4daf4a", 1),
     add = TRUE)
# legend
legend("bottomright", bty = "n",
       col = c("#555555", "#4daf4a"),
       legend = c("eBird checklists", "Wood Thrush sightings"),
       pch = 19)
box()
par(new = TRUE, mar = c(0, 0, 3, 0))
title("Wood Thrush eBird Observations\nJune 2013-2022")
```

In this map, the spatial bias in eBird data becomes immediately obvious, for example, notice the large number of checklists areas around Atlanta in the northern part of the state.

Exploring the effort variables is also a valuable exercise. For each effort variable, we'll produce both a histogram and a plot of frequency of detection as a function of that effort variable. The histogram will tell us something about birder behavior. For example, what time of day are most people going birding, and for how long? We may also want to note values of the effort variable that have very few observations; predictions made in these regions may be unreliable due to a lack of data. The detection frequency plots tell us how the probability of detecting a species changes with effort.

### Time of day {#ebird-explore-time}

The chance of an observer detecting a bird when present can be highly dependent on time of day. For example, many species exhibit a peak in detection early in the morning during dawn chorus and a secondary peak early in the evening. With this in mind, the first predictor of detection that we'll explore is the time of day at which a checklist was started. We'll summarize the data in 1 hour intervals, then plot them. Since estimates of detection frequency are unreliable when only a small number of checklists are available, we'll only plot hours for which at least 100 checklists are present.

```{r ebird-explore-time}
#| label: ebird-explore-time
#| fig-asp: 1
# summarize data by hourly bins
breaks <- seq(0, 24)
labels <- breaks[-length(breaks)] + diff(breaks) / 2
checklists_time <- checklists %>% 
  mutate(hour_bins = cut(hours_of_day, 
                         breaks = breaks, 
                         labels = labels,
                         include.lowest = TRUE),
         hour_bins = as.numeric(as.character(hour_bins))) %>% 
  group_by(hour_bins) %>% 
  summarise(n_checklists = n(),
            n_detected = sum(species_observed),
            det_freq = mean(species_observed))

# histogram
g_tod_hist <- ggplot(checklists_time) +
  aes(x = hour_bins, y = n_checklists) +
  geom_segment(aes(xend = hour_bins, y = 0, yend = n_checklists),
               color = "grey50") +
  geom_point() +
  scale_x_continuous(breaks = seq(0, 24, by = 3), limits = c(0, 24)) +
  scale_y_continuous(labels = scales::comma) +
  labs(x = "Hours since midnight",
       y = "# checklists",
       title = "Distribution of observation start times")

# frequency of detection
g_tod_freq <- ggplot(checklists_time %>% filter(n_checklists > 100)) +
  aes(x = hour_bins, y = det_freq) +
  geom_line() +
  geom_point() +
  scale_x_continuous(breaks = seq(0, 24, by = 3), limits = c(0, 24)) +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "Hours since midnight",
       y = "% checklists with detections",
       title = "Detection frequency")

# combine
grid.arrange(g_tod_hist, g_tod_freq)
```

As expected, Wood Thrush detectability is highest early in the morning and quickly falls off as the day progresses. In later chapters, we'll make predictions at the peak time of day for detectability to limit the effect of this variation. The majority of checklist submissions also occurs in the morning; however, there are reasonable numbers of checklists between 6am and 9pm. It's in this region that our model estimates will be most reliable.

### Checklist duration {#ebird-explore-duration}

When we initially extracted the eBird data in Section \@ref(ebird-extract), we restricted observations to those from checklists 5 hours in duration or shorter to reduce variability. Let's see what sort of variation remains in checklist duration.

```{r}
#| label: ebird-explore-duration
#| fig-asp: 1
# summarize data by 30 minute bins
breaks <- seq(0, 5, by = 0.5)
labels <- breaks[-length(breaks)] + diff(breaks) / 2
checklists_duration <- checklists %>% 
  mutate(duration_bins = cut(duration_minutes / 60, 
                             breaks = breaks, 
                             labels = labels,
                             include.lowest = TRUE),
         duration_bins = as.numeric(as.character(duration_bins))) %>% 
  group_by(duration_bins) %>% 
  summarise(n_checklists = n(),
            n_detected = sum(species_observed),
            det_freq = mean(species_observed))

# histogram
g_duration_hist <- ggplot(checklists_duration) +
  aes(x = duration_bins, y = n_checklists) +
  geom_segment(aes(xend = duration_bins, y = 0, yend = n_checklists),
               color = "grey50") +
  geom_point() +
  scale_x_continuous(breaks = 0:5) +
  scale_y_continuous(labels = scales::comma) +
  labs(x = "Checklist duration (hours)",
       y = "# checklists",
       title = "Distribution of checklist durations")

# frequency of detection
g_duration_freq <- ggplot(checklists_duration %>% filter(n_checklists > 100)) +
  aes(x = duration_bins, y = det_freq) +
  geom_line() +
  geom_point() +
  scale_x_continuous(breaks = 0:5) +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "Checklist duration (hours)",
       y = "% checklists with detections",
       title = "Detection frequency")

# combine
grid.arrange(g_duration_hist, g_duration_freq)
```

The majority of checklists are half an hour or shorter and there is a rapid decline in the frequency of checklists with increasing duration. In addition, longer searches yield a higher chance of detecting a Wood Thrush. In many cases, there is a saturation effect, with searches beyond a given length producing little additional benefit; however, here there appears to be a drop off in detection for checklists longer than 3.5 hours.

### Distance traveled {#ebird-explore-distance}

As with checklist duration, we expect *a priori* that the greater the distance someone travels, the greater the probability of encountering at least one Wood Thrush. Let's see if this expectation is met. Note that we have already truncated the data to checklists less than 5 km in length.

```{r}
#| label: ebird-explore-distance
#| fig-asp: 1
# summarize data by 500m bins
breaks <- seq(0, 5, by = 0.5)
labels <- breaks[-length(breaks)] + diff(breaks) / 2
checklists_dist <- checklists %>% 
  mutate(dist_bins = cut(effort_distance_km, 
                         breaks = breaks, 
                         labels = labels,
                         include.lowest = TRUE),
         dist_bins = as.numeric(as.character(dist_bins))) %>% 
  group_by(dist_bins) %>% 
  summarise(n_checklists = n(),
            n_detected = sum(species_observed),
            det_freq = mean(species_observed))

# histogram
g_dist_hist <- ggplot(checklists_dist) +
  aes(x = dist_bins, y = n_checklists) +
  geom_segment(aes(xend = dist_bins, y = 0, yend = n_checklists),
               color = "grey50") +
  geom_point() +
  scale_x_continuous(breaks = 0:5) +
  scale_y_continuous(labels = scales::comma) +
  labs(x = "Distance travelled (km)",
       y = "# checklists",
       title = "Distribution of distance travelled")

# frequency of detection
g_dist_freq <- ggplot(checklists_dist %>% filter(n_checklists > 100)) +
  aes(x = dist_bins, y = det_freq) +
  geom_line() +
  geom_point() +
  scale_x_continuous(breaks = 0:5) +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "Distance travelled (km)",
       y = "% checklists with detections",
       title = "Detection frequency")

# combine
grid.arrange(g_dist_hist, g_dist_freq)
```

As with duration, the majority of observations are from short checklists (less than half a kilometer). One fortunate consequence of this is that most checklists will be contained within a small area within which habitat is not likely to show high variability. In chapter \@ref{envvar}, we will summarize land cover data within circles 2.5 km in diameter, centered on each checklist, and it appears that the vast majority of checklists will stay contained within this area.

### Number of observers {#ebird-explore-observers}

Finally, let's consider the number of observers whose observation are being reported in each checklist. We expect that at least up to some number of observers, reporting rates will increase; however, in working with these data we have found cases of declining detection rates for very large groups. With this in mind we have already restricted checklists to those with 10 or fewer observers, thus removing the very largest groups (prior to filtering, some checklists had as many as 180 observers!).

```{r ebird-explore-observers, fig.asp = 1}
#| label: ebird-explore-observers
#| fig-asp: 1
# summarize data
breaks <- 0:10
labels <- 1:10
checklists_obs <- checklists %>% 
  mutate(obs_bins = cut(number_observers, 
                        breaks = breaks, 
                        label = labels,
                        include.lowest = TRUE),
         obs_bins = as.numeric(as.character(obs_bins))) %>% 
  group_by(obs_bins) %>% 
  summarise(n_checklists = n(),
            n_detected = sum(species_observed),
            det_freq = mean(species_observed))

# histogram
g_obs_hist <- ggplot(checklists_obs) +
  aes(x = obs_bins, y = n_checklists) +
  geom_segment(aes(xend = obs_bins, y = 0, yend = n_checklists),
               color = "grey50") +
  geom_point() +
  scale_x_continuous(breaks = 1:10) +
  scale_y_continuous(labels = scales::comma) +
  labs(x = "# observers",
       y = "# checklists",
       title = "Distribution of the number of observers")

# frequency of detection
g_obs_freq <- ggplot(checklists_obs %>% filter(n_checklists > 100)) +
  aes(x = obs_bins, y = det_freq) +
  geom_line() +
  geom_point() +
  scale_x_continuous(breaks = 1:10) +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "# observers",
       y = "% checklists with detections",
       title = "Detection frequency")

# combine
grid.arrange(g_obs_hist, g_obs_freq)
```

There is no discernable pattern amongst the noise here, likely because there are so few checklists with more than 3 observers.
