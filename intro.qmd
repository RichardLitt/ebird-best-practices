---
output: html_document
editor_options: 
  chunk_output_type: console
---

# Introduction and Setup {#sec-intro}

## Introduction {#sec-intro-intro}

Citizen science data are increasingly making important contributions to ecological research and conservation. One of the most common forms of citizen science data is derived from members of the public recording species observations. [eBird](https://ebird.org/) [@sullivanEBirdEnterpriseIntegrated2014] is the largest of these biological citizen science programs. The eBird database contains well over one billion bird observations from every country in the world, with observations of nearly every bird species on Earth. The eBird database is valuable to researchers across the globe, due to its year-round, broad spatial coverage, high volumes of [open access](https://en.wikipedia.org/wiki/Open_data) data, and applications to many ecological questions. These data have been widely used in scientific research to study phenology, species distributions, population trends, evolution, behavior, global change, and conservation. However, robust inference with eBird data requires careful processing of the data to address the challenges associated with citizen science datasets. This guide, and the [associated paper](https://onlinelibrary.wiley.com/doi/10.1111/ddi.13271) [@johnstonAnalyticalGuidelinesIncrease2021], outlines a set of best practices for addressing these challenges and making reliable estimates of species distributions from eBird data.

The next chapter provides an [introduction to eBird data](ebird.qmd#sec-ebird-intro), then demonstrates how to [access](ebird.qmd#sec-ebird-download) and [prepare](ebird.qmd#sec-ebird-zf) the data for modeling. The following chapter covers preparing [environmental variables](envvar.qmd) to be used as model predictors. The remaining two chapters demonstrate different species distribution models that can be fit using these data: [encounter rate models](encounter.qmd) and [relative abundance models](abundance.qmd). Although the examples used throughout this guide focus on eBird data, in many cases the techniques they illustrate also apply to similar citizen science datasets.

## Background knowledge {#sec-intro-background}

To understand the code examples used throughout this guide, some knowledge of the programming language [R](https://www.r-project.org/) is required. If you don't meet this requirement, or begin to feel lost trying to understand the code used in this guide, we suggest consulting one of the excellent free resources available online for learning R. For those with little or no prior programming experience, [Hands-On Programming with R](https://rstudio-education.github.io/hopr/) is an excellent introduction. For those with some familiarity with the basics of R that want to take their skills to the next level, we suggest [R for Data Science](https://r4ds.hadley.nz/) as the best resource for learning how to work with data within R.

### Tidyverse {#sec-intro-background-tidyverse}

Throughout this guide, we use packages from the [Tidyverse](https://www.tidyverse.org/), an opinionated collection of R packages designed for data science. Packages such as [`ggplot2`](https://ggplot2.tidyverse.org/), for data visualization, and [`dplyr`](https://dplyr.tidyverse.org/), for data manipulation, are two of the most well known Tidyverse packages; however, there are many more. In the following chapters, we often use Tidyverse functions without explanation. If you encounter a function you're unfamiliar with, consult the documentation for help (e.g. `?mutate` to see help for the `dplyr` function `mutate()`). More generally, the free online guide [R for Data Science](https://r4ds.hadley.nz/) by [Hadley Wickham](https://hadley.nz/) is the best introduction to working with data in R using the Tidyverse.

The one piece of the Tidyverse that we will cover here, because it is ubiquitous throughout this guide and unfamiliar to many, is the pipe operator `%>%`. The pipe operator takes the expression to the left of it and "pipes" it into the first argument of the expression on the right, i.e. one can replace `f(x)` with `x %>% f()`. The pipe makes code significantly more readable by avoiding nested function calls, reducing the need for intermediate variables, and making sequential operations read left-to-right. For example, to add a new variable to a data frame, then summarize using a grouping variable, the following are equivalent:

```{r}
#| label: intro-background-tidyverse
library(dplyr)

# pipes
mtcars %>% 
  mutate(wt_kg = 454 * wt) %>% 
  group_by(cyl) %>% 
  summarize(wt_kg = mean(wt_kg))

# intermediate variables
mtcars_kg <- mutate(mtcars, wt_kg = 454 * wt)
mtcars_grouped <- group_by(mtcars_kg, cyl)
summarize(mtcars_grouped, wt_kg = mean(wt_kg))

# nested function calls
summarize(
  group_by(
    mutate(mtcars, wt_kg = 454 * wt),
    cyl
  ),
  wt_kg = mean(wt_kg)
)
```

Once you become familiar with the pipe operator, we believe you'll find the the above example using the pipe the easiest of the three to read and interpret.

::: {.callout-caution icon="false"}
## Exercise

Rewrite the following code using pipes:

```{r}
#| label: intro-tidyverse-ex
set.seed(1)
round(log(runif(10, min = 0.5)), 1)
```
:::

::: {.callout-note icon="false" collapse="true"}
## Solution

```{r}
#| label: intro-tidyverse-sol
set.seed(1)
runif(10, min = 0.5) %>% 
  log() %>% 
  round(digits = 1)
```
:::

### Working with spatial data in R {#sec-intro-background-spatial}

Some familiarity with the main spatial R packages `sf` and `terra` will be necessary to following along with this guide. The free online book [Geocomputation with R](https://r.geocompx.org/) is a good resource on working with spatial data in R.

## Setup {#sec-intro-setup}

### Data package {#sec-intro-data}

The next two chapters of this guide focus on obtaining and preparing eBird data and environmental variables for the modeling that will occur in the remaining chapters. These steps can be time consuming and laborious. If you'd like to skip straight to the analysis, [download this package of prepared data](https://github.com/ebird/ebird-best-practices/raw/main/data-raw/ebird-best-practices-data.zip). Unzipping this file should produce two directories: `data/` and `data-raw/`. Move both these directories so they are subdirectory of your RStudio project folder. This will allow you to jump right in to the modeling and ensure that you're using exactly the same data as was used when creating this guide. This is a good option if you don't have a fast enough internet connection to download the eBird data.

### Software {#sec-intro-setup-software}

The examples throughout this website use the programming language **R** [@rcoreteamLanguageEnvironmentStatistical2023] to work with eBird data. If you don't have R installed, [download it now](https://cloud.r-project.org/), if you already have R, there's a good chance you have an outdated version, so [update it to the latest version now](https://cloud.r-project.org/). R is updated regularly, and **it is important that you have the most recent version of R** to avoid headaches when installing packages. We suggest checking every couple months to see if a new version has been released.

We strongly encourage R users to use **RStudio**. RStudio is not required to follow along with this guide; however, it will make your R experience significantly better. If you don't have RStudio, [download it now](https://posit.co/download/rstudio-desktop/#download), if you already have it, [update it](https://posit.co/download/rstudio-desktop/#download) because new versions with useful additional features are regularly released.

Due to the large size of the eBird dataset, working with it requires the Unix command-line utility AWK. You won't need to use AWK directly, since the R package `auk` does this hard work for you, but you do need AWK to be installed on your computer. Linux and Mac users should already have AWK installed on their machines; however, Windows user will need to [install Cygwin](https://www.cygwin.com/) to gain access to AWK. Cygwin is free software that allows Windows users to use Unix tools. Cygwin should be installed in the default location (C:/cygwin/bin/gawk.exe or C:/cygwin64/bin/gawk.exe) in order for everything to work correctly. Note: there's no need to do anything at the "Select Utilities" screen, AWK will be installed by default.

### R packages {#sec-intro-setup-packages}

The examples in this guide use a variety of R packages for accessing eBird data, working with spatial data, data processing and manipulation, and model training. To install all the packages necessary to work through this guide, run the following code:

```{r}
#| label: intro-setup-packages
#| eval: false
if (!requireNamespace("remotes", quietly = TRUE)) {
  install.packages("remotes")
}
remotes::install_github("ebird/ebird-best-practices")
```

Note that several of the spatial packages require dependencies. If installing these packages fails, consult the [instructions for installing dependencies on the `sf` package website](https://r-spatial.github.io/sf/#installing). Finally, **ensure all R packages are updated** to their most recent versions by clicking on the Update button on the Packages tab in RStudio.

### eBird data access {#sec-intro-setup-ebird}

Access to the eBird database is provided via the [eBird Basic Dataset (EBD)](https://science.ebird.org/en/use-ebird-data/download-ebird-data-products) as tab-separated text files. To access the EBD, begin by [creating an eBird account and signing in](https://secure.birds.cornell.edu/cassso/account/create). Then visit the [eBird Data Access page](https://ebird.org/data/download) and fill out the data access request form. eBird data access is free for most uses; however, you will need to request access in order to download the EBD. Filling out the access request form allows eBird to keep track of the number of people using the data and obtain information on the applications for which the data are used.

Once you've been granted access to the EBD, you will be able to download either the entire eBird dataset or subsets for specific species, regions, or time periods. This is covered in more detail in the [next chapter](ebird.qmd).

### GIS data {#sec-intro-setup-gis}

Throughout this guide, we'll be producing maps of species distributions. To provide context for these distributions, we'll need GIS data for political boundaries. [Natural Earth](https://www.naturalearthdata.com/) is the best source for a range of tightly integrated vector and raster GIS data for producing professional cartographic maps. The R package, [`rnaturalearth`](https://github.com/ropensci/rnaturalearth) provides a convenient method for accessing these data from within R.

The data package mentioned in @sec-intro-data contains a GeoPackage with all the necessary GIS data. However, for reference, the following code was used to generate the GIS dataset. Running this code will create a GeoPackage containing the necessary spatial layers in `data/gis-data.gpkg`.

```{r}
#| label: intro-setup-gis
#| eval: false
library(dplyr)
library(rnaturalearth)
library(sf)

# file to save spatial data
gpkg_file <- "data/gis-data.gpkg"
dir.create(dirname(gpkg_file), showWarnings = FALSE, recursive = TRUE)

# political boundaries
# land border with lakes removed
ne_land <- ne_download(scale = 50, category = "cultural",
                       type = "admin_0_countries_lakes",
                       returnclass = "sf") %>%
  filter(CONTINENT %in% c("North America", "South America")) %>%
  st_set_precision(1e6) %>%
  st_union()
# country boundaries
ne_countries <- ne_download(scale = 50, category = "cultural",
                       type = "admin_0_countries_lakes",
                       returnclass = "sf") %>%
  select(country = ADMIN, country_code = ISO_A2)
# state boundaries for united states
ne_states <- ne_download(scale = 50, category = "cultural",
                       type = "admin_1_states_provinces",
                       returnclass = "sf") %>% 
  filter(iso_a2 == "US") %>% 
  select(state = name, state_code = iso_3166_2)
# country lines
# downloaded globally then filtered to north america with st_intersect()
ne_country_lines <- ne_download(scale = 50, category = "cultural",
                                type = "admin_0_boundary_lines_land",
                                returnclass = "sf") %>% 
  st_geometry()
ne_country_lines <- st_intersects(ne_country_lines, ne_land, sparse = FALSE) %>%
  as.logical() %>%
  {ne_country_lines[.]}
# states, north america
ne_state_lines <- ne_download(scale = 50, category = "cultural",
                              type = "admin_1_states_provinces_lines",
                              returnclass = "sf") %>%
  filter(ADM0_A3 %in% c("USA", "CAN")) %>%
  mutate(iso_a2 = recode(ADM0_A3, USA = "US", CAN = "CAN")) %>% 
  select(country = ADM0_NAME, country_code = iso_a2)

# save all layers to a geopackage
unlink(gpkg_file)
write_sf(ne_land, gpkg_file, "ne_land")
write_sf(ne_countries, gpkg_file, "ne_countries")
write_sf(ne_states, gpkg_file, "ne_states")
write_sf(ne_country_lines, gpkg_file, "ne_country_lines")
write_sf(ne_state_lines, gpkg_file, "ne_state_lines")
```
